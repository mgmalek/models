{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "outside-yield",
   "metadata": {},
   "source": [
    "# Soft Actor-Critic (SAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gym.envs.classic_control import PendulumEnv\n",
    "from gym.envs.mujoco import HalfCheetahEnv, HopperEnv, Walker2dEnv\n",
    "\n",
    "from sac import SAC, SACAgent, SACConfig\n",
    "from sac.rl import EnvWrapper, ReplayBuffer, RandomContinuousAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SACConfig(env=Walker2dEnv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "sac = SAC(config).cuda()\n",
    "sac_agent = SACAgent(sac.policy_network, discrete_actions=False)\n",
    "random_agent = RandomContinuousAgent(config.action_dim, config.action_min, config.action_max)\n",
    "replay_buffer = ReplayBuffer(config.buffer_size, config.batch_size)\n",
    "env_wrapper = EnvWrapper(config.env, random_agent, config.max_episode_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Initial Data\n",
    "replay_buffer.extend([env_wrapper.step() for _ in range(config.random_steps)])\n",
    "\n",
    "env_wrapper.update_agent(sac_agent)\n",
    "replay_buffer.extend([env_wrapper.step() for _ in range(config.initial_policy_steps)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise One Episode (before training)\n",
    "env_wrapper.test(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "test_returns = []\n",
    "env_wrapper.reset_statistics()\n",
    "while env_wrapper.total_steps < config.total_train_steps:\n",
    "    for _ in range(config.env_steps):\n",
    "        replay_buffer.extend([env_wrapper.step()])\n",
    "\n",
    "    for batch_idx in range(config.training_steps):\n",
    "        states, actions, rewards, next_states, is_done = replay_buffer.sample()\n",
    "        sac.step(states, actions, rewards, next_states, is_done)\n",
    "    \n",
    "    if (env_wrapper.total_steps % 1000) < config.env_steps:\n",
    "        test_return = env_wrapper.test(render=False)\n",
    "        test_returns.append(test_return)\n",
    "        print( \n",
    "            f\"Step: {env_wrapper.total_steps}\\t\"\n",
    "            f\"Episode: {env_wrapper.total_episodes}\\t\"\n",
    "            f\"Test Return: {test_return:6.2f}\\t\"\n",
    "            f\"Temperature: {sac.temperature.log_temperature.exp().item():8.4f}\"\n",
    "        )\n",
    "        \n",
    "        torch.save(sac, f\"{config.env.__name__.replace('Env', '')}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise One Episode (after training)\n",
    "env_wrapper.test(render=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
