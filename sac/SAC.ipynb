{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "scientific-symphony",
   "metadata": {},
   "source": [
    "# Soft Actor-Critic (SAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym\n",
    "from gym.envs.classic_control import PendulumEnv\n",
    "from gym.envs.mujoco import HalfCheetahEnv, HopperEnv, HumanoidEnv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from src import SACConfig, RandomAgent, SACAgent, EnvWrapper, ReplayBuffer, SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SACConfig(\n",
    "    env=HopperEnv,\n",
    "    observation_dim=11,\n",
    "    action_dim=3,\n",
    "    temperature=1.0,\n",
    "    total_train_steps=1_000_000,\n",
    "    action_min=-1.0,\n",
    "    action_max=1.0,\n",
    "    max_episode_length=10_000,\n",
    "    env_steps=1,\n",
    "    training_steps=1,\n",
    "    adjust_temperature=True,\n",
    "    random_steps=10_000,\n",
    "    initial_policy_steps=1_000,\n",
    "    num_q_networks=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Networks, Agents, Dataset and Environment\n",
    "sac = SAC(config).cuda()\n",
    "# sac = torch.load(\"humanoid.pt\")\n",
    "random_agent = RandomAgent(config)\n",
    "agent = SACAgent(sac.policy_network, config)\n",
    "dataset = ReplayBuffer(config)\n",
    "env_wrapper = EnvWrapper(config, random_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Initial Data\n",
    "dataset.extend([env_wrapper.step() for _ in range(config.random_steps)])\n",
    "\n",
    "env_wrapper.agent = agent\n",
    "dataset.extend([env_wrapper.step() for _ in range(config.initial_policy_steps)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_wrapper.test(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "test_returns = []\n",
    "episode_idx = len(env_wrapper.ep_returns)\n",
    "while env_wrapper.total_steps < config.total_train_steps:\n",
    "    for _ in range(config.env_steps):\n",
    "        dataset.extend([env_wrapper.step()])\n",
    "\n",
    "    for batch_idx in range(config.training_steps):\n",
    "        states, actions, rewards, next_states, is_done = dataset.sample()\n",
    "        sac.train(states, actions, rewards, next_states, is_done)\n",
    "    \n",
    "    if (env_wrapper.total_steps % 500) < config.env_steps:\n",
    "        test_return = env_wrapper.test(render=False)\n",
    "        test_returns.append(test_return)\n",
    "        print(f\"Step: {env_wrapper.total_steps}\\tEpisode: {env_wrapper.num_episodes}\\tTest Return: {test_return:6.2f}\\tTemperature: {sac.temperature.log_temperature.exp().item():8.4f}\")\n",
    "        torch.save(sac, \"humanoid.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_wrapper.test(render=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
